{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Prediction with Imbalanced Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mary Donovan Martello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Test Different Subsets of Input Features for Optimizing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import argmax\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#stop unnecessary warnings from printing to the screen\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook uses two datasets that were cleaned and prepared in the 1_EDA_Prep notebook.  One of the datasets replaces some of the original variables with the Months_Late engineered features and the second dataset replaces some of the original variables with both the Months_Late and Payment_Ratio engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a dataframe\n",
    "\n",
    "df1 = pd.read_csv('logDefaultRev1.csv')\n",
    "df2 = pd.read_csv('logDefaultRev2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>MONTHS_LATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>10.819798</td>\n",
       "      <td>12.157764</td>\n",
       "      <td>11.451880</td>\n",
       "      <td>12.121908</td>\n",
       "      <td>12.185186</td>\n",
       "      <td>11.599122</td>\n",
       "      <td>12.815479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.901377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.707962</td>\n",
       "      <td>7.090910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>12.676079</td>\n",
       "      <td>12.318723</td>\n",
       "      <td>11.767754</td>\n",
       "      <td>12.289720</td>\n",
       "      <td>12.339830</td>\n",
       "      <td>11.875079</td>\n",
       "      <td>12.907014</td>\n",
       "      <td>7.824446</td>\n",
       "      <td>7.824446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.476580</td>\n",
       "      <td>7.783641</td>\n",
       "      <td>7.378384</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.988984</td>\n",
       "      <td>12.206078</td>\n",
       "      <td>12.623996</td>\n",
       "      <td>12.257488</td>\n",
       "      <td>12.610621</td>\n",
       "      <td>12.657464</td>\n",
       "      <td>12.339112</td>\n",
       "      <td>13.100394</td>\n",
       "      <td>8.748464</td>\n",
       "      <td>8.612685</td>\n",
       "      <td>8.612685</td>\n",
       "      <td>8.612685</td>\n",
       "      <td>8.517393</td>\n",
       "      <td>8.517393</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>11.002117</td>\n",
       "      <td>12.311630</td>\n",
       "      <td>11.735957</td>\n",
       "      <td>12.285069</td>\n",
       "      <td>12.346786</td>\n",
       "      <td>11.826144</td>\n",
       "      <td>12.886411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.517393</td>\n",
       "      <td>7.828835</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>8.006701</td>\n",
       "      <td>8.006701</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>12.542548</td>\n",
       "      <td>12.615709</td>\n",
       "      <td>12.246783</td>\n",
       "      <td>12.584776</td>\n",
       "      <td>12.658428</td>\n",
       "      <td>12.360976</td>\n",
       "      <td>13.100157</td>\n",
       "      <td>8.779711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.564863</td>\n",
       "      <td>9.605822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.517393</td>\n",
       "      <td>1.94591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default  SEX  EDUCATION  MARRIAGE       AGE  LIMIT_BAL  BILL_AMT1  \\\n",
       "0        1    1          1         2  3.401197  10.819798  12.157764   \n",
       "1        1    1          2         2  3.401197  12.676079  12.318723   \n",
       "2        1    1          1         1  3.988984  12.206078  12.623996   \n",
       "3        0    2          2         2  3.295837  11.002117  12.311630   \n",
       "4        0    1          2         1  3.737670  12.542548  12.615709   \n",
       "\n",
       "   BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0  11.451880  12.121908  12.185186  11.599122  12.815479  0.000000  7.901377   \n",
       "1  11.767754  12.289720  12.339830  11.875079  12.907014  7.824446  7.824446   \n",
       "2  12.257488  12.610621  12.657464  12.339112  13.100394  8.748464  8.612685   \n",
       "3  11.735957  12.285069  12.346786  11.826144  12.886411  0.000000  8.517393   \n",
       "4  12.246783  12.584776  12.658428  12.360976  13.100157  8.779711  0.000000   \n",
       "\n",
       "   PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  MONTHS_LATE  \n",
       "0  0.000000  7.707962  7.090910  0.000000      1.94591  \n",
       "1  0.000000  8.476580  7.783641  7.378384      1.94591  \n",
       "2  8.612685  8.612685  8.517393  8.517393      1.94591  \n",
       "3  7.828835  1.945910  8.006701  8.006701      1.94591  \n",
       "4  9.564863  9.605822  0.000000  8.517393      1.94591  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['default', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'LIMIT_BAL',\n",
       "       'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5',\n",
       "       'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5',\n",
       "       'PAY_AMT6', 'MONTHS_LATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>MONTHS_LATE</th>\n",
       "      <th>PAYMENT_RATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>10.819798</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>0.038110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>12.676079</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>0.037397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.988984</td>\n",
       "      <td>12.206078</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>0.037338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>11.002117</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>0.038758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>12.542548</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>0.046396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default  SEX  EDUCATION  MARRIAGE       AGE  LIMIT_BAL  MONTHS_LATE  \\\n",
       "0        1    1          1         2  3.401197  10.819798      1.94591   \n",
       "1        1    1          2         2  3.401197  12.676079      1.94591   \n",
       "2        1    1          1         1  3.988984  12.206078      1.94591   \n",
       "3        0    2          2         2  3.295837  11.002117      1.94591   \n",
       "4        0    1          2         1  3.737670  12.542548      1.94591   \n",
       "\n",
       "   PAYMENT_RATIO  \n",
       "0       0.038110  \n",
       "1       0.037397  \n",
       "2       0.037338  \n",
       "3       0.038758  \n",
       "4       0.046396  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Dataframes for Testing Feature Subsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1\n",
    "\n",
    "# use get_dummies method for encoding categorical variables only to create subsets\n",
    "\n",
    "# convert categorical data to numbers \n",
    "#get the categorical data\n",
    "cat_features = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "df_cat1 = df1[cat_features]\n",
    "\n",
    "# create dummy variable dataframe for categorical values \n",
    "dfDumm1 = pd.get_dummies(df_cat1)\n",
    "\n",
    "# create a whole features dataset that can be used for train and validation data splitting\n",
    "# combine the numerical features and the dummie features together\n",
    "dfNum1 = df1.drop(['SEX', 'EDUCATION', 'MARRIAGE', 'default'], axis = 1)\n",
    "X1 = pd.concat([dfNum1, dfDumm1], axis=1, ignore_index=True)\n",
    "# create a whole target dataset that can be used for train and validation data splitting\n",
    "y1 =  df1['default']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGE', 'LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
       "       'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
       "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'MONTHS_LATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNum1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SEX', 'EDUCATION', 'MARRIAGE'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDumm1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = ['AGE', 'LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5',\n",
    "       'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'MONTHS_LATE',\n",
    "           'SEX', 'EDUCATION', 'MARRIAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.columns = colNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2\n",
    "\n",
    "# use get_dummies method for encoding categorical variables only to create subsets\n",
    "\n",
    "# convert categorical data to numbers \n",
    "#get the categorical data\n",
    "cat_features = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "df_cat2 = df2[cat_features]\n",
    "\n",
    "# create dummy variable dataframe for categorical values \n",
    "dfDumm2 = pd.get_dummies(df_cat2)\n",
    "\n",
    "# create a whole features dataset that can be used for train and validation data splitting\n",
    "# combine the numerical features and the dummie features together\n",
    "dfNum2 = df2.drop(['SEX', 'EDUCATION', 'MARRIAGE', 'default'], axis = 1)\n",
    "X2 = pd.concat([dfNum2, dfDumm2], axis=1, ignore_index=True)\n",
    "# create a whole target dataset that can be used for train and validation data splitting\n",
    "y2 =  df2['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGE', 'LIMIT_BAL', 'MONTHS_LATE', 'PAYMENT_RATIO'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNum2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames2 = ['AGE', 'LIMIT_BAL', 'MONTHS_LATE', 'PAYMENT_RATIO', 'SEX', 'EDUCATION', 'MARRIAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.columns = colNames2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different subsets of input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df1 for the next 9 cells.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.14\n"
     ]
    }
   ],
   "source": [
    "# baseline of all variables\n",
    "fullset = X1.loc[:, ['AGE', 'LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n",
    "       'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
    "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'MONTHS_LATE', 'SEX', 'EDUCATION',\n",
    "       'MARRIAGE']]\n",
    "\n",
    "# separate data into training and validation \n",
    "FTrain, FTest, yTrain_F, yTest_F = train_test_split(fullset, y1, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(FTrain)\n",
    "# scale the training dataset\n",
    "FTrain = scaler.transform(FTrain)\n",
    "# scale the test dataset\n",
    "FTest = scaler.transform(FTest)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRF = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRF.fit(FTrain, yTrain_F)\n",
    "\n",
    "# predict on test set\n",
    "yhatF = modelLRF.predict(FTest)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_F, yhatF)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.18\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# lR coefficients top 5 important features\n",
    "subset1 = X1.loc[:, [\n",
    " 'MONTHS_LATE',\n",
    " 'LIMIT_BAL',\n",
    " 'MARRIAGE'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S1Train, S1Test, yTrain_S1, yTest_S1 = train_test_split(subset1, y1, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S1Train)\n",
    "# scale the training dataset\n",
    "S1Train = scaler.transform(S1Train)\n",
    "# scale the test dataset\n",
    "S1Test = scaler.transform(S1Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS1 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS1.fit(S1Train, yTrain_S1)\n",
    "\n",
    "# predict on test set\n",
    "yhatS1 = modelLRS1.predict(S1Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S1, yhatS1)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.31\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# LR coefficients top 2 important features\n",
    "subset2 = X1.loc[:, [\n",
    " 'MONTHS_LATE',\n",
    " 'LIMIT_BAL'\n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S2Train, S2Test, yTrain_S2, yTest_S2 = train_test_split(subset2, y1, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S2Train)\n",
    "# scale the training dataset\n",
    "S2Train = scaler.transform(S2Train)\n",
    "# scale the test dataset\n",
    "S2Test = scaler.transform(S2Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS2 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS2.fit(S2Train, yTrain_S2)\n",
    "\n",
    "# predict on test set\n",
    "yhatS2 = modelLRS2.predict(S2Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S2, yhatS2)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.21\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# CART DecisionTreeClassifier \n",
    "# 3 of top 4 important features\n",
    "subset3 = X1.loc[:, [\n",
    " 'MONTHS_LATE',\n",
    "    'AGE', 'LIMIT_BAL'\n",
    " \n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S3Train, S3Test, yTrain_S3, yTest_S3 = train_test_split(subset3, y1, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S3Train)\n",
    "# scale the training dataset\n",
    "S3Train = scaler.transform(S3Train)\n",
    "# scale the test dataset\n",
    "S3Test = scaler.transform(S3Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS3 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS3.fit(S3Train, yTrain_S3)\n",
    "\n",
    "# predict on test set\n",
    "yhatS3 = modelLRS3.predict(S3Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S3, yhatS3)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.21\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# RandomForestClassifier\n",
    "# TOP 4 important features\n",
    "subset4 = X1.loc[:, [\n",
    " 'MONTHS_LATE',\n",
    "    'AGE', 'BILL_AMT1', 'LIMIT_BAL', \n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S4Train, S4Test, yTrain_S4, yTest_S4 = train_test_split(subset4, y1, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S4Train)\n",
    "# scale the training dataset\n",
    "S4Train = scaler.transform(S4Train)\n",
    "# scale the test dataset\n",
    "S4Test = scaler.transform(S4Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS4 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS4.fit(S4Train, yTrain_S4)\n",
    "\n",
    "# predict on test set\n",
    "yhatS4 = modelLRS4.predict(S4Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S4, yhatS4)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.12\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# Ensemble RandomForestClassifier\n",
    "# TOP 4 important features for Default classifier\n",
    "subset5 = X1.loc[:, [\n",
    " 'MONTHS_LATE', 'BILL_AMT2', 'LIMIT_BAL',\n",
    "    'PAY_AMT1',  'BILL_AMT1', 'PAY_AMT2',\n",
    "    'BILL_AMT6', 'BILL_AMT3'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S5Train, S5Test, yTrain_S5, yTest_S5 = train_test_split(subset5, y1, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S5Train)\n",
    "# scale the training dataset\n",
    "S5Train = scaler.transform(S5Train)\n",
    "# scale the test dataset\n",
    "S5Test = scaler.transform(S5Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS5 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS5.fit(S5Train, yTrain_S5)\n",
    "\n",
    "# predict on test set\n",
    "yhatS5 = modelLRS5.predict(S5Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S5, yhatS5)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.99\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# F statisic -TOP 8\n",
    "subset6 = X1.loc[:, [\n",
    " 'MONTHS_LATE', 'LIMIT_BAL',\n",
    "    'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
    "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S6Train, S6Test, yTrain_S6, yTest_S6 = train_test_split(subset6, y1, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S6Train)\n",
    "# scale the training dataset\n",
    "S6Train = scaler.transform(S6Train)\n",
    "# scale the test dataset\n",
    "S6Test = scaler.transform(S6Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS6 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS6.fit(S6Train, yTrain_S6)\n",
    "\n",
    "# predict on test set\n",
    "yhatS6 = modelLRS6.predict(S6Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S6, yhatS6)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.32\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "\n",
    "# XGBClassifier Scores\n",
    "# Top 3 feature importance minus the Education and Marriage variables\n",
    "subset7 = X1.loc[:, [\n",
    " 'MONTHS_LATE', 'LIMIT_BAL', 'BILL_AMT1'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S7Train, S7Test, yTrain_S7, yTest_S7 = train_test_split(subset7, y1, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S7Train)\n",
    "# scale the training dataset\n",
    "S7Train = scaler.transform(S7Train)\n",
    "# scale the test dataset\n",
    "S7Test = scaler.transform(S7Test)\n",
    "\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS7 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS7.fit(S7Train, yTrain_S7)\n",
    "\n",
    "# predict on test set\n",
    "yhatS7 = modelLRS7.predict(S7Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S7, yhatS7)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.62\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# RFECV and MFA\n",
    "subset8 = X1.loc[:, [\n",
    " 'MONTHS_LATE' \n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S8Train, S8Test, yTrain_S8, yTest_S8 = train_test_split(subset8, y1, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S8Train)\n",
    "# scale the training dataset\n",
    "S8Train = scaler.transform(S8Train)\n",
    "# scale the test dataset\n",
    "S8Test = scaler.transform(S8Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS8 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS8.fit(S8Train, yTrain_S8)\n",
    "\n",
    "# predict on test set\n",
    "yhatS8 = modelLRS8.predict(S8Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S8, yhatS8)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export best subset df to csv\n",
    "subset8.to_csv('subset8df1Rev.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df2 data for remainder of cells.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGE', 'LIMIT_BAL', 'MONTHS_LATE', 'PAYMENT_RATIO', 'SEX', 'EDUCATION',\n",
       "       'MARRIAGE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.12\n"
     ]
    }
   ],
   "source": [
    "# baseline of all variables\n",
    "fullset = X2.loc[:, ['AGE', 'LIMIT_BAL', 'MONTHS_LATE', 'PAYMENT_RATIO', 'SEX', 'EDUCATION',\n",
    "       'MARRIAGE']]\n",
    "\n",
    "# separate data into training and validation \n",
    "FTrain, FTest, yTrain_F, yTest_F = train_test_split(fullset, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(FTrain)\n",
    "# scale the training dataset\n",
    "FTrain = scaler.transform(FTrain)\n",
    "# scale the test dataset\n",
    "FTest = scaler.transform(FTest)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRF = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRF.fit(FTrain, yTrain_F)\n",
    "\n",
    "# predict on test set\n",
    "yhatF = modelLRF.predict(FTest)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_F, yhatF)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.18\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# LR coefficients top 3 important features\n",
    "subset21 = X2.loc[:, [\n",
    " 'MONTHS_LATE',\n",
    " 'LIMIT_BAL', 'MARRIAGE'\n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S2Train, S2Test, yTrain_S2, yTest_S2 = train_test_split(subset21, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S2Train)\n",
    "# scale the training dataset\n",
    "S2Train = scaler.transform(S2Train)\n",
    "# scale the test dataset\n",
    "S2Test = scaler.transform(S2Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS2 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS2.fit(S2Train, yTrain_S2)\n",
    "\n",
    "# predict on test set\n",
    "yhatS2 = modelLRS2.predict(S2Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S2, yhatS2)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.27\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# CART DecisionTreeClassifier AND Random Forest Classifier AND Ensemble RF\n",
    "# TOP 4 important features\n",
    "subset22 = X2.loc[:, [\n",
    " 'PAYMENT_RATIO', 'MONTHS_LATE',\n",
    "    'AGE', 'LIMIT_BAL'\n",
    " \n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S3Train, S3Test, yTrain_S3, yTest_S3 = train_test_split(subset22, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S3Train)\n",
    "# scale the training dataset\n",
    "S3Train = scaler.transform(S3Train)\n",
    "# scale the test dataset\n",
    "S3Test = scaler.transform(S3Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS3 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS3.fit(S3Train, yTrain_S3)\n",
    "\n",
    "# predict on test set\n",
    "yhatS3 = modelLRS3.predict(S3Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S3, yhatS3)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.23\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "\n",
    "# XGBClassifier Scores\n",
    "# Top 6 feature importance minus the Education and Marriage variables\n",
    "subset23 = X2.loc[:, [\n",
    " 'MONTHS_LATE', 'PAYMENT_RATIO', 'LIMIT_BAL', 'AGE', 'EDUCATION', 'SEX',\n",
    "       \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S7Train, S7Test, yTrain_S7, yTest_S7 = train_test_split(subset23, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S7Train)\n",
    "# scale the training dataset\n",
    "S7Train = scaler.transform(S7Train)\n",
    "# scale the test dataset\n",
    "S7Test = scaler.transform(S7Test)\n",
    "\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS7 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS7.fit(S7Train, yTrain_S7)\n",
    "\n",
    "# predict on test set\n",
    "yhatS7 = modelLRS7.predict(S7Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S7, yhatS7)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.28\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# F statisic -TOP 3\n",
    "subset24 = X2.loc[:, [\n",
    " 'MONTHS_LATE', 'LIMIT_BAL', 'PAYMENT_RATIO'\n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S6Train, S6Test, yTrain_S6, yTest_S6 = train_test_split(subset24, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S6Train)\n",
    "# scale the training dataset\n",
    "S6Train = scaler.transform(S6Train)\n",
    "# scale the test dataset\n",
    "S6Test = scaler.transform(S6Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS6 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS6.fit(S6Train, yTrain_S6)\n",
    "\n",
    "# predict on test set\n",
    "yhatS6 = modelLRS6.predict(S6Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S6, yhatS6)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.52\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# \n",
    "subset25 = X2.loc[:, [\n",
    " 'PAYMENT_RATIO', 'MONTHS_LATE' \n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S6Train, S6Test, yTrain_S6, yTest_S6 = train_test_split(subset25, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S6Train)\n",
    "# scale the training dataset\n",
    "S6Train = scaler.transform(S6Train)\n",
    "# scale the test dataset\n",
    "S6Test = scaler.transform(S6Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS6 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS6.fit(S6Train, yTrain_S6)\n",
    "\n",
    "# predict on test set\n",
    "yhatS6 = modelLRS6.predict(S6Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S6, yhatS6)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.27\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# Ensemble RandomForestClassifier\n",
    "# TOP 4 important features for Default classifier\n",
    "subset52 = X2.loc[:, [\n",
    " 'MONTHS_LATE', 'PAYMENT_RATIO', 'LIMIT_BAL', 'AGE'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S5Train, S5Test, yTrain_S5, yTest_S5 = train_test_split(subset52, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S5Train)\n",
    "# scale the training dataset\n",
    "S5Train = scaler.transform(S5Train)\n",
    "# scale the test dataset\n",
    "S5Test = scaler.transform(S5Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS5 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS5.fit(S5Train, yTrain_S5)\n",
    "\n",
    "# predict on test set\n",
    "yhatS5 = modelLRS5.predict(S5Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S5, yhatS5)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.53\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# RFECV and MFA\n",
    "subset82 = X2.loc[:, [\n",
    " 'MONTHS_LATE' \n",
    "    \n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S8Train, S8Test, yTrain_S8, yTest_S8 = train_test_split(subset82, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# define the scaler\n",
    "scaler = StandardScaler()\n",
    "# fit on the training dataset\n",
    "scaler.fit(S8Train)\n",
    "# scale the training dataset\n",
    "S8Train = scaler.transform(S8Train)\n",
    "# scale the test dataset\n",
    "S8Test = scaler.transform(S8Test)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS8 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS8.fit(S8Train, yTrain_S8)\n",
    "\n",
    "# predict on test set\n",
    "yhatS8 = modelLRS8.predict(S8Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S8, yhatS8)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export best subset df to csv\n",
    "subset25.to_csv('subset25df2Rev.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
